{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe300441-1152-46f0-b81c-a6927a81d61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import yfinance as yf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e53a5bbf-66d5-4416-8792-15eb481382a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carina_fp = '/home/ginger/code/gderiddershanghai/DVA_Team_173/data_full/raw/twitter_data/kaggle/carina_tweets_cleaned.csv'\n",
    "kenny_fp = '/home/ginger/code/gderiddershanghai/DVA_Team_173/data_full/raw/twitter_data/kenny/kenny_stock_tweets_labelled.csv'\n",
    "# big_fp = '/home/ginger/code/gderiddershanghai/DVA_Team_173/data_full/raw/twitter_data/big_twitter/Tweet.csv'\n",
    "# jason_top = '/home/ginger/code/gderiddershanghai/DVA_Team_173/data_full/processed/IEEE/top.csv'\n",
    "# jason_middle = '/home/ginger/code/gderiddershanghai/DVA_Team_173/data_full/processed/IEEE/mid.csv'\n",
    "# jason_bottom = '/home/ginger/code/gderiddershanghai/DVA_Team_173/data_full/processed/IEEE/bottom.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "038bd728-5c9e-44bc-a8df-da3ba113db10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carina_df = pd.read_csv(carina_fp)\n",
    "kenny_df = pd.read_csv(kenny_fp)\n",
    "# big_df = pd.read_csv(big_fp)\n",
    "# jason_top_df = pd.read_csv(jason_top)\n",
    "# jason_middle_df = pd.read_csv(jason_middle)\n",
    "# jason_bottom_df = pd.read_csv(jason_bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "656e2374-5578-4400-8369-3768ad367a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index(['Created_at', 'Tweet', 'Stock_ticker', 'Score', 'Source'], dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac3b3abe-62ff-42be-9cf2-8be08ca60fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEET</th>\n",
       "      <th>STOCK</th>\n",
       "      <th>DATE</th>\n",
       "      <th>LAST_PRICE</th>\n",
       "      <th>1_DAY_RETURN</th>\n",
       "      <th>2_DAY_RETURN</th>\n",
       "      <th>3_DAY_RETURN</th>\n",
       "      <th>7_DAY_RETURN</th>\n",
       "      <th>PX_VOLUME</th>\n",
       "      <th>VOLATILITY_10D</th>\n",
       "      <th>VOLATILITY_30D</th>\n",
       "      <th>LSTM_POLARITY</th>\n",
       "      <th>TEXTBLOB_POLARITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @IndiaHistorypic: 1994::Young @sundarpichai...</td>\n",
       "      <td>Google</td>\n",
       "      <td>31/01/2017</td>\n",
       "      <td>820.19</td>\n",
       "      <td>0.004438</td>\n",
       "      <td>0.030286</td>\n",
       "      <td>0.030286</td>\n",
       "      <td>0.035772</td>\n",
       "      <td>2020180.0</td>\n",
       "      <td>21.549</td>\n",
       "      <td>14.953</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @Google: \"If you have the feeling that some...</td>\n",
       "      <td>Google</td>\n",
       "      <td>31/01/2017</td>\n",
       "      <td>820.19</td>\n",
       "      <td>0.004438</td>\n",
       "      <td>0.030286</td>\n",
       "      <td>0.030286</td>\n",
       "      <td>0.035772</td>\n",
       "      <td>2020180.0</td>\n",
       "      <td>21.549</td>\n",
       "      <td>14.953</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TWEET   STOCK        DATE  \\\n",
       "0  RT @IndiaHistorypic: 1994::Young @sundarpichai...  Google  31/01/2017   \n",
       "1  RT @Google: \"If you have the feeling that some...  Google  31/01/2017   \n",
       "\n",
       "   LAST_PRICE  1_DAY_RETURN  2_DAY_RETURN  3_DAY_RETURN  7_DAY_RETURN  \\\n",
       "0      820.19      0.004438      0.030286      0.030286      0.035772   \n",
       "1      820.19      0.004438      0.030286      0.030286      0.035772   \n",
       "\n",
       "   PX_VOLUME  VOLATILITY_10D  VOLATILITY_30D  LSTM_POLARITY  TEXTBLOB_POLARITY  \n",
       "0  2020180.0          21.549          14.953           -1.0               0.00  \n",
       "1  2020180.0          21.549          14.953           -1.0              -0.55  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jason_top_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a8b6c5c9-f179-454f-9b90-a712fb641f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_jason(df):\n",
    "    df['Created_at'] = df['DATE']\n",
    "    df['Company_name'] = df['STOCK']\n",
    "    df['Stock_ticker'] = 99\n",
    "    df['Tweet'] = df['TWEET']\n",
    "    df['Score'] = df['TEXTBLOB_POLARITY']\n",
    "    df['Source'] = 'Jason'\n",
    "    df = df[['Created_at', 'Tweet', 'Stock_ticker', 'Company_name', 'Score', 'Source']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9f30d58f-fbce-4352-85c7-b01402bf49fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "jason_top_df = change_jason(jason_top_df)\n",
    "jason_middle_df =change_jason(jason_middle_df)\n",
    "jason_bottom_df = change_jason(jason_bottom_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e001350-661f-4c00-b2d0-b882429714d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Created_at</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Stock_ticker</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Score</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31/01/2017</td>\n",
       "      <td>RT @IndiaHistorypic: 1994::Young @sundarpichai...</td>\n",
       "      <td>99</td>\n",
       "      <td>Google</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31/01/2017</td>\n",
       "      <td>RT @Google: \"If you have the feeling that some...</td>\n",
       "      <td>99</td>\n",
       "      <td>Google</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>Jason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31/01/2017</td>\n",
       "      <td>RT @IBMWatson: Welcome @Apple, #ACLU, #AAAI, @...</td>\n",
       "      <td>99</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Jason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31/01/2017</td>\n",
       "      <td>RT @ColMorrisDavis: My family owned a @Ford de...</td>\n",
       "      <td>99</td>\n",
       "      <td>Ford</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31/01/2017</td>\n",
       "      <td>RT @ThatBitchFromNJ: Google's sponsored ad for...</td>\n",
       "      <td>99</td>\n",
       "      <td>Google</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>Jason</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Created_at                                              Tweet  \\\n",
       "0  31/01/2017  RT @IndiaHistorypic: 1994::Young @sundarpichai...   \n",
       "1  31/01/2017  RT @Google: \"If you have the feeling that some...   \n",
       "2  31/01/2017  RT @IBMWatson: Welcome @Apple, #ACLU, #AAAI, @...   \n",
       "3  31/01/2017  RT @ColMorrisDavis: My family owned a @Ford de...   \n",
       "4  31/01/2017  RT @ThatBitchFromNJ: Google's sponsored ad for...   \n",
       "\n",
       "   Stock_ticker Company_name  Score Source  \n",
       "0            99       Google   0.00  Jason  \n",
       "1            99       Google  -0.55  Jason  \n",
       "2            99        Apple   1.00  Jason  \n",
       "3            99         Ford   0.00  Jason  \n",
       "4            99       Google  -0.10  Jason  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jason_top_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd96df0-1be6-4b35-9bf3-25d95eebd57e",
   "metadata": {},
   "source": [
    "## Getting names for Carina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "493a14ad-be6e-4b36-a961-382587390a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Created_at</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Stock_ticker</th>\n",
       "      <th>Score</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-09 23:59:51+00:00</td>\n",
       "      <td>@KennyDegu very very little volume. With $10T ...</td>\n",
       "      <td>SPX</td>\n",
       "      <td>-0.637271</td>\n",
       "      <td>Carina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-04-09 23:58:55+00:00</td>\n",
       "      <td>#ES_F achieved Target 2780 closing above 50% #...</td>\n",
       "      <td>SPX</td>\n",
       "      <td>0.919818</td>\n",
       "      <td>Carina</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 Created_at  \\\n",
       "0           0  2020-04-09 23:59:51+00:00   \n",
       "1           1  2020-04-09 23:58:55+00:00   \n",
       "\n",
       "                                               Tweet Stock_ticker     Score  \\\n",
       "0  @KennyDegu very very little volume. With $10T ...          SPX -0.637271   \n",
       "1  #ES_F achieved Target 2780 closing above 50% #...          SPX  0.919818   \n",
       "\n",
       "   Source  \n",
       "0  Carina  \n",
       "1  Carina  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carina_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2278ad2-2b47-41ad-acf5-da844a242ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_name(ticker):\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        return stock.info.get(\"longName\", \"Unknown\")\n",
    "    except Exception:\n",
    "        return \"Unknown\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51075497-0dc6-4a11-8b3b-38c952883573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carina_df.head()[\"Stock_ticker\"].apply(get_company_name) # TOOOO FUCKING SLOOOOOOWWWWWW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95bbbd3f-585a-46d1-b18d-252e89a80eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_dic_fp = '/home/ginger/code/gderiddershanghai/DVA_Team_173/data_full/raw/twitter_data/kaggle/sp500.csv'\n",
    "stock_dic_df = pd.read_csv(stock_dic_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3ae3573-84e9-436b-a7c6-3e5513da67aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M Company</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>A.O. Smith Corp</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie Inc.</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABMD</td>\n",
       "      <td>ABIOMED Inc</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol                 Name       Sector\n",
       "0    MMM           3M Company  Industrials\n",
       "1    AOS      A.O. Smith Corp  Industrials\n",
       "2    ABT  Abbott Laboratories  Health Care\n",
       "3   ABBV          AbbVie Inc.  Health Care\n",
       "4   ABMD          ABIOMED Inc  Health Care"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_dic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a5e98c6-2a8b-4ac6-9744-06a341c358b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_dic_df = stock_dic_df.rename(columns={\"Symbol\": \"Stock_ticker\", \"Name\": \"Company_Name\"})\n",
    "carina_df = carina_df.merge(stock_dic_df, on=\"Stock_ticker\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad6d8322-ff42-480c-a65f-304095c05b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "carina_df = carina_df[~carina_df['Company_Name'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8da36ee6-ea62-4b5a-8a9b-842d6c78b92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "carina_df = carina_df[['Created_at', 'Tweet', 'Stock_ticker', 'Score', 'Source','Company_Name', 'Sector']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad628c81-6814-4541-82e8-40504b0a29d0",
   "metadata": {},
   "source": [
    "# Ssame thing for the jason dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b921c8da-1be6-48d5-8aab-b67e005623a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "jason_df = pd.concat([jason_top_df, jason_middle_df, jason_bottom_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8c6794c9-4a8d-4585-a5d9-d6019dbcefe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "jason_df['Company_Name'] = jason_df['Company_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6ef1bd8d-54bb-42ae-b3fe-9a762718c93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358689"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jason_df.merge(stock_dic_df, on=\"Company_Name\", how=\"left\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "acb93ab9-656a-4f01-928a-6a566f40c785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975196567811817"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jason_df.merge(stock_dic_df, on=\"Company_Name\", how=\"left\" )['Stock_ticker_y'].isna().sum() / jason_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bd8ce6b5-8c3b-4526-9dca-7cd4c9297844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ford        47907\n",
       "Facebook    47684\n",
       "Google      31657\n",
       "Next        30908\n",
       "Apple       29160\n",
       "Name: Company_name, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jason_df['Company_name'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "80e23db1-765a-4e0c-980b-114ac01e65ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Created_at</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Stock_ticker</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Score</th>\n",
       "      <th>Source</th>\n",
       "      <th>Company_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31/01/2017</td>\n",
       "      <td>RT @IndiaHistorypic: 1994::Young @sundarpichai...</td>\n",
       "      <td>99</td>\n",
       "      <td>Google</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jason</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31/01/2017</td>\n",
       "      <td>RT @Google: \"If you have the feeling that some...</td>\n",
       "      <td>99</td>\n",
       "      <td>Google</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>Jason</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Created_at                                              Tweet  \\\n",
       "0  31/01/2017  RT @IndiaHistorypic: 1994::Young @sundarpichai...   \n",
       "1  31/01/2017  RT @Google: \"If you have the feeling that some...   \n",
       "\n",
       "   Stock_ticker Company_name  Score Source Company_Name  \n",
       "0            99       Google   0.00  Jason       Google  \n",
       "1            99       Google  -0.55  Jason       Google  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jason_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "59db0828-2f42-4ded-96e9-dc18d39aab57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock_ticker</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M Company</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>A.O. Smith Corp</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stock_ticker     Company_Name       Sector\n",
       "0          MMM       3M Company  Industrials\n",
       "1          AOS  A.O. Smith Corp  Industrials"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_dic_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "58097e3b-9ca4-435f-9b97-3de59f763101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using chat to create a dictionary because I can't fucking find the ticker symbols\n",
    "tickers = {\n",
    "    '21CF': None,  # No longer traded, was FOXA before Disney acquired it\n",
    "    'ASOS': 'ASC.L',  # London Stock Exchange\n",
    "    'AT&T': 'T',  # NYSE\n",
    "    'Adobe': 'ADBE',  # NASDAQ\n",
    "    'Allianz': 'ALV.DE',  # XETRA\n",
    "    'Amazon': 'AMZN',  # NASDAQ\n",
    "    'American Express': 'AXP',  # NYSE\n",
    "    'Apple': 'AAPL',  # NASDAQ\n",
    "    'AstraZeneca': 'AZN',  # NASDAQ, LSE: AZN.L\n",
    "    'Audi': 'VOW.DE',  # Part of Volkswagen\n",
    "    'Aviva': 'AV.L',  # LSE\n",
    "    'BASF': 'BAS.DE',  # XETRA\n",
    "    'BMW': 'BMW.DE',  # XETRA\n",
    "    'BP': 'BP',  # NYSE, LSE: BP.L\n",
    "    'Bank of America': 'BAC',  # NYSE\n",
    "    'Bayer': 'BAYN.DE',  # XETRA\n",
    "    'BlackRock': 'BLK',  # NYSE\n",
    "    'Boeing': 'BA',  # NYSE\n",
    "    'Burberry': 'BRBY.L',  # LSE\n",
    "    'CBS': 'PARA',  # NYSE (Now part of Paramount Global)\n",
    "    'CVS Health': 'CVS',  # NYSE\n",
    "    'Cardinal Health': 'CAH',  # NYSE\n",
    "    'Carrefour': 'CA.PA',  # Euronext Paris\n",
    "    'Chevron': 'CVX',  # NYSE\n",
    "    'Cisco': 'CSCO',  # NASDAQ\n",
    "    'Citigroup': 'C',  # NYSE\n",
    "    'CocaCola': 'KO',  # NYSE\n",
    "    'Colgate': 'CL',  # NYSE\n",
    "    'Comcast': 'CMCSA',  # NASDAQ\n",
    "    'Costco': 'COST',  # NASDAQ\n",
    "    'Danone': 'BN.PA',  # Euronext Paris\n",
    "    'Deutsche Bank': 'DB',  # NYSE\n",
    "    'Disney': 'DIS',  # NYSE\n",
    "    'Equinor': 'EQNR',  # NYSE\n",
    "    'Expedia': 'EXPE',  # NASDAQ\n",
    "    'Exxon': 'XOM',  # NYSE\n",
    "    'Facebook': 'META',  # NASDAQ (formerly FB)\n",
    "    'FedEx': 'FDX',  # NYSE\n",
    "    'Ford': 'F',  # NYSE\n",
    "    'GSK': 'GSK',  # NYSE, LSE: GSK.L\n",
    "    'General Electric': 'GE',  # NYSE\n",
    "    'Gillette': None,  # Subsidiary of P&G\n",
    "    'Goldman Sachs': 'GS',  # NYSE\n",
    "    'Google': 'GOOGL',  # NASDAQ\n",
    "    'Groupon': 'GRPN',  # NASDAQ\n",
    "    'H&M': 'HM-B.ST',  # Stockholm Exchange\n",
    "    'HP': 'HPQ',  # NYSE\n",
    "    'HSBC': 'HSBC',  # NYSE, LSE: HSBA.L\n",
    "    'Heineken': 'HEIA.AS',  # Euronext Amsterdam\n",
    "    'Home Depot': 'HD',  # NYSE\n",
    "    'Honda': 'HMC',  # NYSE\n",
    "    'Hyundai': 'HYMTF',  # OTC\n",
    "    'IBM': 'IBM',  # NYSE\n",
    "    'Intel': 'INTC',  # NASDAQ\n",
    "    'JPMorgan': 'JPM',  # NYSE\n",
    "    'John Deere': 'DE',  # NYSE\n",
    "    \"Kellogg's\": 'K',  # NYSE (now split into K and KLG)\n",
    "    'Kroger': 'KR',  # NYSE\n",
    "    \"L'Oreal\": 'OR.PA',  # Euronext Paris\n",
    "    'Mastercard': 'MA',  # NYSE\n",
    "    \"McDonald's\": 'MCD',  # NYSE\n",
    "    'Microsoft': 'MSFT',  # NASDAQ\n",
    "    'Morgan Stanley': 'MS',  # NYSE\n",
    "    'Nestle': 'NESN.S',  # SIX Swiss Exchange\n",
    "    'Netflix': 'NFLX',  # NASDAQ\n",
    "    'Next': 'NXT.L',  # LSE\n",
    "    'Nike': 'NKE',  # NYSE\n",
    "    'Nissan': '7201.T',  # Tokyo Exchange\n",
    "    'Oracle': 'ORCL',  # NYSE\n",
    "    'P&G': 'PG',  # NYSE\n",
    "    'PayPal': 'PYPL',  # NASDAQ\n",
    "    'Pepsi': 'PEP',  # NASDAQ\n",
    "    'Pfizer': 'PFE',  # NYSE\n",
    "    'Reuters': None,  # Part of Thomson Reuters (NYSE: TRI)\n",
    "    'Ryanair': 'RYAAY',  # NASDAQ\n",
    "    'SAP': 'SAP',  # NYSE, XETRA\n",
    "    'Samsung': '005930.KQ',  # Korea Exchange\n",
    "    'Santander': 'SAN',  # NYSE, BMAD: SAN.MC\n",
    "    'Shell': 'SHEL',  # NYSE, LSE\n",
    "    'Siemens': 'SIE.DE',  # XETRA\n",
    "    'Sony': 'SONY',  # NYSE\n",
    "    'Starbucks': 'SBUX',  # NASDAQ\n",
    "    'TMobile': 'TMUS',  # NASDAQ\n",
    "    'Tesco': 'TSCO.L',  # LSE\n",
    "    'Thales': 'HO.PA',  # Euronext Paris\n",
    "    'Toyota': 'TM',  # NYSE\n",
    "    'TripAdvisor': 'TRIP',  # NASDAQ\n",
    "    'UPS': 'UPS',  # NYSE\n",
    "    'Verizon': 'VZ',  # NYSE\n",
    "    'Viacom': 'PARA',  # NYSE (now Paramount Global)\n",
    "    'Visa': 'V',  # NYSE\n",
    "    'Vodafone': 'VOD',  # NASDAQ, LSE: VOD.L\n",
    "    'Volkswagen': 'VOW3.DE',  # XETRA\n",
    "    'Walmart': 'WMT',  # NYSE\n",
    "    'Wells Fargo': 'WFC',  # NYSE\n",
    "    'Yahoo': None,  # Acquired by Verizon, no longer publicly traded\n",
    "    'adidas': 'ADS.DE',  # XETRA\n",
    "    'bookingcom': 'BKNG',  # NASDAQ (Booking Holdings)\n",
    "    'eBay': 'EBAY',  # NASDAQ\n",
    "    'easyJet': 'EZJ.L',  # LSE\n",
    "    'salesforce.com': 'CRM'  # NYSE\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ca6737d4-fb9d-467b-8cc6-9058c1c78bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "jason_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ff4cbfd8-e61f-4f05-bb84-132178a0b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "jason_df['Stock_ticker'] = jason_df['Company_Name'].map(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "efd4ee5c-3cbc-4878-ab6d-5fd8262fda91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Created_at</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Stock_ticker</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Score</th>\n",
       "      <th>Source</th>\n",
       "      <th>Company_Name_x</th>\n",
       "      <th>Company_Name_y</th>\n",
       "      <th>Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31/01/2017</td>\n",
       "      <td>RT @IndiaHistorypic: 1994::Young @sundarpichai...</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Google</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jason</td>\n",
       "      <td>Google</td>\n",
       "      <td>Alphabet Inc. (Class A)</td>\n",
       "      <td>Communication Services</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Created_at                                              Tweet Stock_ticker  \\\n",
       "0  31/01/2017  RT @IndiaHistorypic: 1994::Young @sundarpichai...        GOOGL   \n",
       "\n",
       "  Company_name  Score Source Company_Name_x           Company_Name_y  \\\n",
       "0       Google    0.0  Jason         Google  Alphabet Inc. (Class A)   \n",
       "\n",
       "                   Sector  \n",
       "0  Communication Services  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jason_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "33c1ec6b-56aa-4832-ae7b-a34b7d36027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_tickers = [\n",
    "    'T', 'ADBE', 'AMZN', 'AXP', 'AAPL', 'BAC', 'BA', 'CVS', 'CAH', 'CVX',\n",
    "    'CSCO', 'C', 'KO', 'CL', 'CMCSA', 'COST', 'DIS', 'XOM', 'META', 'FDX',\n",
    "    'F', 'GE', 'GS', 'GOOGL', 'GOOG', 'HD', 'IBM', 'INTC', 'JPM', 'KR',\n",
    "    'MA', 'MCD', 'MSFT', 'MS', 'NFLX', 'NKE', 'ORCL', 'PG', 'PYPL', 'PEP',\n",
    "    'PFE', 'SBUX', 'TMUS', 'UPS', 'VZ', 'V', 'WMT', 'WFC', 'CRM']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "286971e2-c495-4ebc-aacd-06ceef790353",
   "metadata": {},
   "outputs": [],
   "source": [
    "jason_df = jason_df[jason_df['Stock_ticker'].isin(sp500_tickers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5c3e5f11-939f-4e38-9ca1-223d4565040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "jason_df = jason_df.merge(stock_dic_df, on=\"Stock_ticker\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e2a3e9-5011-49ee-a1b5-9d95dbedaa0d",
   "metadata": {},
   "source": [
    "## KENNY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "20f21231-4407-4931-9a10-14c13890ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "kenny_df['Stock_ticker'] = kenny_df['Stock Name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e79eacee-9ad0-4e40-bb1d-d50f8504e331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(stock_dic_df['Stock_ticker']=='TSLA').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "3cc3eb75-f71a-4f06-8bc6-172983b40d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Created_at</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Stock_ticker</th>\n",
       "      <th>Score</th>\n",
       "      <th>Source</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-29 23:41:16+00:00</td>\n",
       "      <td>Mainstream media has done an amazing job at br...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>predicted_score</td>\n",
       "      <td>Kenny</td>\n",
       "      <td>Company Name</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-29 23:24:43+00:00</td>\n",
       "      <td>Tesla delivery estimates are at around 364k fr...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>predicted_score</td>\n",
       "      <td>Kenny</td>\n",
       "      <td>Company Name</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-29 23:18:08+00:00</td>\n",
       "      <td>3/ Even if I include 63.0M unvested RSUs as of...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>predicted_score</td>\n",
       "      <td>Kenny</td>\n",
       "      <td>Company Name</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-29 22:40:07+00:00</td>\n",
       "      <td>@RealDanODowd @WholeMarsBlog @Tesla Hahaha why...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>predicted_score</td>\n",
       "      <td>Kenny</td>\n",
       "      <td>Company Name</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-29 22:27:05+00:00</td>\n",
       "      <td>@RealDanODowd @Tesla Stop trying to kill kids,...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>predicted_score</td>\n",
       "      <td>Kenny</td>\n",
       "      <td>Company Name</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>2022-05-31 11:51:02+00:00</td>\n",
       "      <td>I'm excited about $TSLA this week. Are you?</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>predicted_score</td>\n",
       "      <td>Kenny</td>\n",
       "      <td>Company Name</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>2022-05-31 11:29:56+00:00</td>\n",
       "      <td>Tomorrow @ 11am CT we will host a YouTube even...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>predicted_score</td>\n",
       "      <td>Kenny</td>\n",
       "      <td>Company Name</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>2022-05-31 11:05:48+00:00</td>\n",
       "      <td>Report: $TSLA Giga Shanghai Plant Restores 70%...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>predicted_score</td>\n",
       "      <td>Kenny</td>\n",
       "      <td>Company Name</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>2022-05-31 10:42:33+00:00</td>\n",
       "      <td>I didn't sell because I'm not a bull. I sold b...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>predicted_score</td>\n",
       "      <td>Kenny</td>\n",
       "      <td>Company Name</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>2022-05-31 10:33:22+00:00</td>\n",
       "      <td>Welcome back everyone! I had great time in Mia...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>predicted_score</td>\n",
       "      <td>Kenny</td>\n",
       "      <td>Company Name</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Created_at  \\\n",
       "0      2022-09-29 23:41:16+00:00   \n",
       "1      2022-09-29 23:24:43+00:00   \n",
       "2      2022-09-29 23:18:08+00:00   \n",
       "3      2022-09-29 22:40:07+00:00   \n",
       "4      2022-09-29 22:27:05+00:00   \n",
       "...                          ...   \n",
       "79995  2022-05-31 11:51:02+00:00   \n",
       "79996  2022-05-31 11:29:56+00:00   \n",
       "79997  2022-05-31 11:05:48+00:00   \n",
       "79998  2022-05-31 10:42:33+00:00   \n",
       "79999  2022-05-31 10:33:22+00:00   \n",
       "\n",
       "                                                   Tweet Stock_ticker  \\\n",
       "0      Mainstream media has done an amazing job at br...         TSLA   \n",
       "1      Tesla delivery estimates are at around 364k fr...         TSLA   \n",
       "2      3/ Even if I include 63.0M unvested RSUs as of...         TSLA   \n",
       "3      @RealDanODowd @WholeMarsBlog @Tesla Hahaha why...         TSLA   \n",
       "4      @RealDanODowd @Tesla Stop trying to kill kids,...         TSLA   \n",
       "...                                                  ...          ...   \n",
       "79995        I'm excited about $TSLA this week. Are you?         TSLA   \n",
       "79996  Tomorrow @ 11am CT we will host a YouTube even...         TSLA   \n",
       "79997  Report: $TSLA Giga Shanghai Plant Restores 70%...         TSLA   \n",
       "79998  I didn't sell because I'm not a bull. I sold b...         TSLA   \n",
       "79999  Welcome back everyone! I had great time in Mia...         TSLA   \n",
       "\n",
       "                 Score Source  Company_Name                  Sector  \n",
       "0      predicted_score  Kenny  Company Name  Consumer Discretionary  \n",
       "1      predicted_score  Kenny  Company Name  Consumer Discretionary  \n",
       "2      predicted_score  Kenny  Company Name  Consumer Discretionary  \n",
       "3      predicted_score  Kenny  Company Name  Consumer Discretionary  \n",
       "4      predicted_score  Kenny  Company Name  Consumer Discretionary  \n",
       "...                ...    ...           ...                     ...  \n",
       "79995  predicted_score  Kenny  Company Name  Consumer Discretionary  \n",
       "79996  predicted_score  Kenny  Company Name  Consumer Discretionary  \n",
       "79997  predicted_score  Kenny  Company Name  Consumer Discretionary  \n",
       "79998  predicted_score  Kenny  Company Name  Consumer Discretionary  \n",
       "79999  predicted_score  Kenny  Company Name  Consumer Discretionary  \n",
       "\n",
       "[80000 rows x 7 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kenny_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0b244c54-569f-4a06-997c-b8eceda7a1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Communication Services',\n",
       " 'Consumer Discretionary',\n",
       " 'Consumer Staples',\n",
       " 'Energy',\n",
       " 'Financials',\n",
       " 'Health Care',\n",
       " 'Industrials',\n",
       " 'Information Technology',\n",
       " 'Materials',\n",
       " 'Real Estate',\n",
       " 'Utilities'}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stock_dic_df.Sector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "94feafcc-11ab-4fe7-90cd-d6a6655148d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using chat again\n",
    "kenny_df['Sector'] = 'Consumer Discretionary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "085b1db9-3dc1-44df-9dba-0ffd8bf97372",
   "metadata": {},
   "outputs": [],
   "source": [
    "kenny_df['Created_at'] = kenny_df['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d2392d3e-5165-4af6-800f-a386e08be3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kenny_df['Source'] = 'Kenny'\n",
    "kenny_df['Score'] = kenny_df['predicted_score']\n",
    "kenny_df['Company_Name'] = kenny_df['Company Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "3d77948c-bc90-4c33-972f-c6ec727c2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jason_df['Company_Name'] = jason_df['Company_name']\n",
    "jason_df = jason_df[['Created_at', 'Tweet', 'Stock_ticker', 'Score', 'Source',\n",
    "       'Company_Name', 'Sector']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "56e4e57c-8bd4-41d2-9188-f7e65b3f6578",
   "metadata": {},
   "outputs": [],
   "source": [
    "kenny_df = kenny_df[carina_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "0c3f3e1c-b193-4ccf-90dd-cae05d4e39bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([kenny_df, jason_df, carina_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "bbf3a8f9-5206-4088-ab75-cab141bf7c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 628827 entries, 0 to 628826\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Created_at    628827 non-null  object \n",
      " 1   Tweet         628827 non-null  object \n",
      " 2   Stock_ticker  628827 non-null  object \n",
      " 3   Score         628827 non-null  float64\n",
      " 4   Source        628827 non-null  object \n",
      " 5   Company_Name  628827 non-null  object \n",
      " 6   Sector        581143 non-null  object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 33.6+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "0d6c39d3-23f2-4b84-954c-5e496df3b4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df['Created_at'] = pd.to_datetime(merged_df['Created_at'], errors='coerce').dt.normalize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "eca60f06-ab3b-443b-8661-de02d9adabfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Created_at</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Stock_ticker</th>\n",
       "      <th>Score</th>\n",
       "      <th>Source</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-29 23:41:16+00:00</td>\n",
       "      <td>Mainstream media has done an amazing job at br...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.549933</td>\n",
       "      <td>Kenny</td>\n",
       "      <td>Tesla, Inc.</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-29 23:24:43+00:00</td>\n",
       "      <td>Tesla delivery estimates are at around 364k fr...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.104447</td>\n",
       "      <td>Kenny</td>\n",
       "      <td>Tesla, Inc.</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-29 23:18:08+00:00</td>\n",
       "      <td>3/ Even if I include 63.0M unvested RSUs as of...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.879566</td>\n",
       "      <td>Kenny</td>\n",
       "      <td>Tesla, Inc.</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-29 22:40:07+00:00</td>\n",
       "      <td>@RealDanODowd @WholeMarsBlog @Tesla Hahaha why...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.094424</td>\n",
       "      <td>Kenny</td>\n",
       "      <td>Tesla, Inc.</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-29 22:27:05+00:00</td>\n",
       "      <td>@RealDanODowd @Tesla Stop trying to kill kids,...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>-0.550417</td>\n",
       "      <td>Kenny</td>\n",
       "      <td>Tesla, Inc.</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628822</th>\n",
       "      <td>2020-04-09 11:35:12+00:00</td>\n",
       "      <td>The first informative #App on Pivot Points.\\nS...</td>\n",
       "      <td>ETFC</td>\n",
       "      <td>-0.508957</td>\n",
       "      <td>Carina</td>\n",
       "      <td>E*Trade</td>\n",
       "      <td>Financials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628823</th>\n",
       "      <td>2020-04-09 11:35:08+00:00</td>\n",
       "      <td>We always try to learn from our mistakes! \\n$E...</td>\n",
       "      <td>ETN</td>\n",
       "      <td>-1.070149</td>\n",
       "      <td>Carina</td>\n",
       "      <td>Eaton Corporation</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628824</th>\n",
       "      <td>2020-04-09 11:35:06+00:00</td>\n",
       "      <td>$JPM to no longer offer loans to small busines...</td>\n",
       "      <td>JPM</td>\n",
       "      <td>0.025878</td>\n",
       "      <td>Carina</td>\n",
       "      <td>JPMorgan Chase &amp; Co.</td>\n",
       "      <td>Financials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628825</th>\n",
       "      <td>2020-04-09 11:35:03+00:00</td>\n",
       "      <td>Brokerages Set Facebook, Inc. $FB Target Price...</td>\n",
       "      <td>FB</td>\n",
       "      <td>0.937436</td>\n",
       "      <td>Carina</td>\n",
       "      <td>Facebook Inc.</td>\n",
       "      <td>Communication Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628826</th>\n",
       "      <td>2020-04-09 11:34:49+00:00</td>\n",
       "      <td>RT @TheStreet: Amazon $AMZN is among the best-...</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-1.070149</td>\n",
       "      <td>Carina</td>\n",
       "      <td>Amazon.com Inc.</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>628827 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Created_at  \\\n",
       "0       2022-09-29 23:41:16+00:00   \n",
       "1       2022-09-29 23:24:43+00:00   \n",
       "2       2022-09-29 23:18:08+00:00   \n",
       "3       2022-09-29 22:40:07+00:00   \n",
       "4       2022-09-29 22:27:05+00:00   \n",
       "...                           ...   \n",
       "628822  2020-04-09 11:35:12+00:00   \n",
       "628823  2020-04-09 11:35:08+00:00   \n",
       "628824  2020-04-09 11:35:06+00:00   \n",
       "628825  2020-04-09 11:35:03+00:00   \n",
       "628826  2020-04-09 11:34:49+00:00   \n",
       "\n",
       "                                                    Tweet Stock_ticker  \\\n",
       "0       Mainstream media has done an amazing job at br...         TSLA   \n",
       "1       Tesla delivery estimates are at around 364k fr...         TSLA   \n",
       "2       3/ Even if I include 63.0M unvested RSUs as of...         TSLA   \n",
       "3       @RealDanODowd @WholeMarsBlog @Tesla Hahaha why...         TSLA   \n",
       "4       @RealDanODowd @Tesla Stop trying to kill kids,...         TSLA   \n",
       "...                                                   ...          ...   \n",
       "628822  The first informative #App on Pivot Points.\\nS...         ETFC   \n",
       "628823  We always try to learn from our mistakes! \\n$E...          ETN   \n",
       "628824  $JPM to no longer offer loans to small busines...          JPM   \n",
       "628825  Brokerages Set Facebook, Inc. $FB Target Price...           FB   \n",
       "628826  RT @TheStreet: Amazon $AMZN is among the best-...         AMZN   \n",
       "\n",
       "           Score  Source          Company_Name                  Sector  \n",
       "0       0.549933   Kenny           Tesla, Inc.  Consumer Discretionary  \n",
       "1       0.104447   Kenny           Tesla, Inc.  Consumer Discretionary  \n",
       "2       0.879566   Kenny           Tesla, Inc.  Consumer Discretionary  \n",
       "3       0.094424   Kenny           Tesla, Inc.  Consumer Discretionary  \n",
       "4      -0.550417   Kenny           Tesla, Inc.  Consumer Discretionary  \n",
       "...          ...     ...                   ...                     ...  \n",
       "628822 -0.508957  Carina               E*Trade              Financials  \n",
       "628823 -1.070149  Carina     Eaton Corporation             Industrials  \n",
       "628824  0.025878  Carina  JPMorgan Chase & Co.              Financials  \n",
       "628825  0.937436  Carina         Facebook Inc.  Communication Services  \n",
       "628826 -1.070149  Carina       Amazon.com Inc.  Consumer Discretionary  \n",
       "\n",
       "[628827 rows x 7 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_fp = '/home/ginger/code/gderiddershanghai/DVA_Team_173/data_full/processed/merged_df.csv'\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96b6f98-d55d-4bb7-8051-dc4d642fc9d9",
   "metadata": {},
   "source": [
    "### BIG DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "dfba8258-e296-4def-be7e-ee52e62694a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_fp = '/home/ginger/code/gderiddershanghai/DVA_Team_173/data_full/raw/twitter_data/big_twitter/big_filtered_labelled.csv'\n",
    "big_df = pd.read_csv(big_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9ff038e1-58db-46a9-bcb4-5849613d646b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1240000, 17)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "54899280-5cff-4e7c-a4fd-4cc3da2f992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df['Score']= big_df['predicted_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8fedeb8c-7390-4936-8bb7-12c5a212fed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df['Created_at'] = pd.to_datetime(big_df['post_date'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a98a101d-7731-48ec-87fd-f73015848451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Created_at', 'Tweet', 'Stock_ticker', 'Score', 'Source',\n",
       "       'Company_Name', 'Sector'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carina_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3c087e38-b5bc-4770-ae1f-46ddd1bd7299",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df['Company_Name'] = big_df['company_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1f6226c5-b285-4d7c-8b74-a0f4fa4e58c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = big_df[['Created_at', 'Tweet', 'Stock_ticker', 'Score', 'Source',\n",
    "       'Company_Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "352d5d38-7156-4fa0-b6a3-6eed4787bb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17405/991924588.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  big_df['Sector'] = big_df['Company_Name'].map(sector_classification)\n"
     ]
    }
   ],
   "source": [
    "sector_classification = {\n",
    "    'Amazon.com': 'Consumer Discretionary',\n",
    "    'Google Inc': 'Communication Services',\n",
    "    'Microsoft': 'Information Technology',\n",
    "    'Tesla Inc': 'Consumer Discretionary',\n",
    "    'apple': 'Information Technology'\n",
    "}\n",
    "\n",
    "big_df['Sector'] = big_df['Company_Name'].map(sector_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "7b22be22-2e27-40c4-91e9-412c2145b553",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = big_df[merged_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "196cea0f-f314-43a6-a0a3-442c9a4f86ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([merged_df, big_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b48e6154-fa7a-4482-806b-02d3faa5f441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(df['Stock_ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "192e265e-ed65-45c4-93e6-24122bf6987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('/home/ginger/code/gderiddershanghai/DVA_Team_173/data_full/processed/iteration1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "ace22a0e-1bb3-4e52-8da4-bce0a1017082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3M Company',\n",
       " 'A.O. Smith Corp',\n",
       " 'ABIOMED Inc',\n",
       " 'AES Corp',\n",
       " 'AFLAC Inc',\n",
       " 'AMETEK Inc.',\n",
       " 'ANSYS',\n",
       " 'AT&T',\n",
       " 'AT&T Inc.',\n",
       " 'AbbVie Inc.',\n",
       " 'Abbott Laboratories',\n",
       " 'Accenture plc',\n",
       " 'Adobe',\n",
       " 'Adobe Inc.',\n",
       " 'Advance Auto Parts',\n",
       " 'Advanced Micro Devices Inc',\n",
       " 'Agilent Technologies Inc',\n",
       " 'Air Products & Chemicals Inc',\n",
       " 'Alaska Air Group Inc',\n",
       " 'Albemarle Corp',\n",
       " 'Alexandria Real Estate Equities',\n",
       " 'Alexion Pharmaceuticals',\n",
       " 'Align Technology',\n",
       " 'Allegion',\n",
       " 'Alliant Energy Corp',\n",
       " 'Allstate Corp',\n",
       " 'Alphabet Inc. (Class A)',\n",
       " 'Alphabet Inc. (Class C)',\n",
       " 'Altria Group Inc',\n",
       " 'Amazon',\n",
       " 'Amazon.com',\n",
       " 'Amazon.com Inc.',\n",
       " 'Ameren Corp',\n",
       " 'American Airlines Group',\n",
       " 'American Electric Power',\n",
       " 'American Express',\n",
       " 'American Express Co',\n",
       " 'American International Group',\n",
       " 'American Water Works Company Inc',\n",
       " 'Ameriprise Financial',\n",
       " 'AmerisourceBergen Corp',\n",
       " 'Amphenol Corp',\n",
       " 'Analog Devices Inc.',\n",
       " 'Anthem',\n",
       " 'Aon plc',\n",
       " 'Apache Corporation',\n",
       " 'Apartment Investment & Management',\n",
       " 'Apple',\n",
       " 'Apple Inc.',\n",
       " 'Applied Materials Inc.',\n",
       " 'Aptiv PLC',\n",
       " 'Archer-Daniels-Midland Co',\n",
       " 'Arista Networks',\n",
       " 'Arthur J. Gallagher & Co.',\n",
       " 'Assurant',\n",
       " 'AutoZone Inc',\n",
       " 'Autodesk Inc.',\n",
       " 'Automatic Data Processing',\n",
       " 'AvalonBay Communities',\n",
       " 'Avery Dennison Corp',\n",
       " 'Ball Corp',\n",
       " 'Bank of America',\n",
       " 'Bank of America Corp',\n",
       " 'Becton Dickinson',\n",
       " 'Best Buy Co. Inc.',\n",
       " 'Biogen Inc.',\n",
       " 'BlackRock',\n",
       " 'Boeing',\n",
       " 'Boeing Company',\n",
       " 'Booking Holdings Inc',\n",
       " 'BorgWarner',\n",
       " 'Boston Properties',\n",
       " 'Boston Scientific',\n",
       " 'Bristol-Myers Squibb',\n",
       " 'Broadcom Inc.',\n",
       " 'Broadridge Financial Solutions',\n",
       " 'C. H. Robinson Worldwide',\n",
       " 'CBRE Group',\n",
       " 'CF Industries Holdings Inc',\n",
       " 'CIGNA Corp.',\n",
       " 'CME Group Inc.',\n",
       " 'CVS Health',\n",
       " 'Cadence Design Systems',\n",
       " 'Capital One Financial',\n",
       " 'Cardinal Health',\n",
       " 'Cardinal Health Inc.',\n",
       " 'Carmax Inc',\n",
       " 'Carnival Corp.',\n",
       " 'Caterpillar Inc.',\n",
       " 'Cboe Global Markets',\n",
       " 'Celanese',\n",
       " 'Centene Corporation',\n",
       " 'CenturyLink Inc',\n",
       " 'Cerner',\n",
       " 'Charter Communications',\n",
       " 'Chevron',\n",
       " 'Chevron Corp.',\n",
       " 'Chipotle Mexican Grill',\n",
       " 'Chubb Limited',\n",
       " 'Cincinnati Financial',\n",
       " 'Cintas Corporation',\n",
       " 'Cisco',\n",
       " 'Cisco Systems',\n",
       " 'Citigroup',\n",
       " 'Citigroup Inc.',\n",
       " 'Citizens Financial Group',\n",
       " 'Coca-Cola Company',\n",
       " 'CocaCola',\n",
       " 'Cognizant Technology Solutions',\n",
       " 'Colgate',\n",
       " 'Colgate-Palmolive',\n",
       " 'Comcast',\n",
       " 'Comcast Corp.',\n",
       " 'Comerica Inc.',\n",
       " 'Constellation Brands',\n",
       " 'Copart Inc',\n",
       " 'Corning Inc.',\n",
       " 'Costco',\n",
       " 'Costco Wholesale Corp.',\n",
       " 'DaVita Inc.',\n",
       " 'Danaher Corp.',\n",
       " 'Darden Restaurants',\n",
       " 'Delta Air Lines Inc.',\n",
       " 'Devon Energy',\n",
       " 'Diamondback Energy',\n",
       " 'Discover Financial Services',\n",
       " 'Disney',\n",
       " 'Dominion Energy',\n",
       " 'Dover Corporation',\n",
       " 'Dow Inc.',\n",
       " 'E*Trade',\n",
       " 'Eastman Chemical',\n",
       " 'Eaton Corporation',\n",
       " 'Ecolab Inc.',\n",
       " 'Edwards Lifesciences',\n",
       " 'Emerson Electric Company',\n",
       " 'Entergy Corp.',\n",
       " 'Equifax Inc.',\n",
       " 'Evergy',\n",
       " 'Eversource Energy',\n",
       " 'Expedia Group',\n",
       " 'Expeditors',\n",
       " 'Exxon',\n",
       " 'Exxon Mobil Corp.',\n",
       " 'F5 Networks',\n",
       " 'FLIR Systems',\n",
       " 'FMC Corporation',\n",
       " 'Facebook',\n",
       " 'Facebook Inc.',\n",
       " 'Fastenal Co',\n",
       " 'FedEx',\n",
       " 'FedEx Corporation',\n",
       " 'Fidelity National Information Services',\n",
       " 'Fifth Third Bancorp',\n",
       " 'FirstEnergy Corp',\n",
       " 'Fiserv Inc',\n",
       " 'FleetCor Technologies Inc',\n",
       " 'Ford',\n",
       " 'Ford Motor Company',\n",
       " 'Fortive Corp',\n",
       " 'Fortune Brands Home & Security',\n",
       " 'Fox Corporation (Class B)',\n",
       " 'Franklin Resources',\n",
       " 'Freeport-McMoRan Inc.',\n",
       " 'General Electric',\n",
       " 'General Mills',\n",
       " 'Genuine Parts',\n",
       " 'Gilead Sciences',\n",
       " 'Global Payments Inc.',\n",
       " 'Goldman Sachs',\n",
       " 'Goldman Sachs Group',\n",
       " 'Google',\n",
       " 'Google Inc',\n",
       " 'Grainger (W.W.) Inc.',\n",
       " 'H&R Block',\n",
       " 'HP Inc.',\n",
       " 'Halliburton Co.',\n",
       " 'Hasbro Inc.',\n",
       " 'Hess Corporation',\n",
       " 'Hilton Worldwide Holdings Inc',\n",
       " 'Home Depot',\n",
       " \"Honeywell Int'l Inc.\",\n",
       " 'Host Hotels & Resorts',\n",
       " 'Humana Inc.',\n",
       " 'Huntington Bancshares',\n",
       " 'IBM',\n",
       " 'IQVIA Holdings Inc.',\n",
       " 'Illinois Tool Works',\n",
       " 'Incyte',\n",
       " 'Intel',\n",
       " 'Intel Corp.',\n",
       " 'Intercontinental Exchange',\n",
       " 'International Business Machines',\n",
       " 'International Flavors & Fragrances',\n",
       " 'International Paper',\n",
       " 'Intuitive Surgical Inc.',\n",
       " 'JPMorgan',\n",
       " 'JPMorgan Chase & Co.',\n",
       " 'Johnson & Johnson',\n",
       " 'Juniper Networks',\n",
       " 'Kansas City Southern',\n",
       " 'Kellogg Co.',\n",
       " 'Kraft Heinz Co',\n",
       " 'Kroger',\n",
       " 'Kroger Co.',\n",
       " 'Lam Research',\n",
       " 'Las Vegas Sands',\n",
       " 'Leggett & Platt',\n",
       " 'Lennar Corp.',\n",
       " 'Lilly (Eli) & Co.',\n",
       " 'Linde plc',\n",
       " 'Live Nation Entertainment',\n",
       " \"Lowe's Cos.\",\n",
       " 'LyondellBasell',\n",
       " 'MGM Resorts International',\n",
       " 'MSCI Inc',\n",
       " 'MarketAxess',\n",
       " \"Marriott Int'l.\",\n",
       " 'Mastercard',\n",
       " 'Mastercard Inc.',\n",
       " 'Maxim Integrated Products Inc',\n",
       " 'McCormick & Co.',\n",
       " \"McDonald's\",\n",
       " \"McDonald's Corp.\",\n",
       " 'Medtronic plc',\n",
       " 'Merck & Co.',\n",
       " 'Mettler Toledo',\n",
       " 'Microchip Technology',\n",
       " 'Microsoft',\n",
       " 'Microsoft Corp.',\n",
       " 'Mohawk Industries',\n",
       " 'Molson Coors Beverage Company',\n",
       " \"Moody's Corp\",\n",
       " 'Morgan Stanley',\n",
       " 'NRG Energy',\n",
       " 'Nasdaq Inc.',\n",
       " 'National Oilwell Varco Inc.',\n",
       " 'NetApp',\n",
       " 'Netflix',\n",
       " 'Netflix Inc.',\n",
       " 'Newmont Corporation',\n",
       " 'NiSource Inc.',\n",
       " 'Nielsen Holdings',\n",
       " 'Nike',\n",
       " 'Nike Inc.',\n",
       " 'Norfolk Southern Corp.',\n",
       " 'Norwegian Cruise Line Holdings',\n",
       " 'Nvidia Corporation',\n",
       " 'ONEOK',\n",
       " 'Occidental Petroleum',\n",
       " 'Old Dominion Freight Line',\n",
       " 'Oracle',\n",
       " 'Oracle Corp.',\n",
       " 'P&G',\n",
       " 'PPG Industries',\n",
       " 'Packaging Corporation of America',\n",
       " 'Parker-Hannifin',\n",
       " 'PayPal',\n",
       " 'Paycom',\n",
       " 'Pentair plc',\n",
       " 'Pepsi',\n",
       " 'PepsiCo Inc.',\n",
       " 'PerkinElmer',\n",
       " 'Pfizer',\n",
       " 'Pfizer Inc.',\n",
       " 'Pinnacle West Capital',\n",
       " 'Procter & Gamble',\n",
       " 'Progressive Corp.',\n",
       " 'Prologis',\n",
       " 'Public Service Enterprise Group (PSEG)',\n",
       " 'Public Storage',\n",
       " 'QUALCOMM Inc.',\n",
       " 'Quest Diagnostics',\n",
       " 'Ralph Lauren Corporation',\n",
       " 'Raymond James Financial Inc.',\n",
       " 'Realty Income Corporation',\n",
       " 'Rockwell Automation Inc.',\n",
       " 'Rollins Inc.',\n",
       " 'Ross Stores',\n",
       " 'Royal Caribbean Group',\n",
       " 'SVB Financial',\n",
       " 'Salesforce.com',\n",
       " 'Schlumberger Ltd.',\n",
       " 'Sealed Air',\n",
       " 'Sempra Energy',\n",
       " 'Sherwin-Williams',\n",
       " 'Simon Property Group Inc',\n",
       " 'Snap-on',\n",
       " 'Southern Company',\n",
       " 'Southwest Airlines',\n",
       " 'Stanley Black & Decker',\n",
       " 'Starbucks',\n",
       " 'Starbucks Corp.',\n",
       " 'State Street Corp.',\n",
       " 'Stryker Corp.',\n",
       " 'Sysco Corp.',\n",
       " 'T. Rowe Price Group',\n",
       " 'TJX Companies Inc.',\n",
       " 'TMobile',\n",
       " 'Target Corp.',\n",
       " 'TechnipFMC',\n",
       " 'Teledyne Technologies',\n",
       " 'Tesla Inc',\n",
       " 'Tesla, Inc.',\n",
       " 'Textron Inc.',\n",
       " 'The Bank of New York Mellon',\n",
       " 'The Clorox Company',\n",
       " 'The Mosaic Company',\n",
       " 'The Walt Disney Company',\n",
       " 'Tractor Supply Company',\n",
       " 'Truist Financial',\n",
       " 'Twitter Inc.',\n",
       " 'U.S. Bancorp',\n",
       " 'UDR Inc.',\n",
       " 'UPS',\n",
       " 'Under Armour (Class C)',\n",
       " 'Union Pacific Corp',\n",
       " 'United Airlines Holdings',\n",
       " 'United Health Group Inc.',\n",
       " 'United Parcel Service',\n",
       " 'Valero Energy',\n",
       " 'Varian Medical Systems',\n",
       " 'Verisk Analytics',\n",
       " 'Verizon',\n",
       " 'Verizon Communications',\n",
       " 'Visa',\n",
       " 'Visa Inc.',\n",
       " 'Vornado Realty Trust',\n",
       " 'Walmart',\n",
       " 'Waste Management Inc.',\n",
       " 'Wells Fargo',\n",
       " 'WestRock',\n",
       " 'Western Union Co',\n",
       " 'Weyerhaeuser',\n",
       " 'Williams Companies',\n",
       " 'Xerox',\n",
       " 'Xilinx',\n",
       " 'Yum! Brands Inc',\n",
       " 'Zimmer Biomet Holdings',\n",
       " 'Zoetis',\n",
       " 'apple',\n",
       " 'eBay Inc.',\n",
       " 'salesforce.com'}"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df['Company_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "15e2fa65-c27f-4eed-aa16-1efbaa9cdeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# switching to chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "e10299d0-b6c3-4f4a-a6b1-06c125c3fc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Dictionary of normalized => canonical\n",
    "synonyms = {\n",
    "    # AT&T\n",
    "    'at&t': 'AT&T Inc.',\n",
    "    'at&t inc': 'AT&T Inc.',\n",
    "\n",
    "    # Adobe\n",
    "    'adobe': 'Adobe Inc.',\n",
    "    'adobe inc': 'Adobe Inc.',\n",
    "\n",
    "    # Amazon\n",
    "    'amazon': 'Amazon.com Inc.',\n",
    "    'amazoncom': 'Amazon.com Inc.',\n",
    "    'amazoncom inc': 'Amazon.com Inc.',\n",
    "\n",
    "    # American Express\n",
    "    'american express': 'American Express Co',\n",
    "    'american express co': 'American Express Co',\n",
    "\n",
    "    # Apple\n",
    "    'apple': 'Apple Inc.',\n",
    "    'apple inc': 'Apple Inc.',\n",
    "\n",
    "    # Bank of America\n",
    "    'bank of america': 'Bank of America Corp',\n",
    "    'bank of america corp': 'Bank of America Corp',\n",
    "\n",
    "    # Boeing\n",
    "    'boeing': 'Boeing Company',\n",
    "    'boeing company': 'Boeing Company',\n",
    "\n",
    "    # Cardinal Health\n",
    "    'cardinal health': 'Cardinal Health Inc.',\n",
    "    'cardinal health inc': 'Cardinal Health Inc.',\n",
    "\n",
    "    # Chevron\n",
    "    'chevron': 'Chevron Corp.',\n",
    "    'chevron corp': 'Chevron Corp.',\n",
    "\n",
    "    # Cisco\n",
    "    'cisco': 'Cisco Systems',\n",
    "    'cisco systems': 'Cisco Systems',\n",
    "\n",
    "    # Citigroup\n",
    "    'citigroup': 'Citigroup Inc.',\n",
    "    'citigroup inc': 'Citigroup Inc.',\n",
    "\n",
    "    # Coca-Cola\n",
    "    'cocacola': 'Coca-Cola Company',\n",
    "    'coca-cola company': 'Coca-Cola Company',\n",
    "\n",
    "    # Colgate\n",
    "    'colgate': 'Colgate-Palmolive',\n",
    "    'colgate-palmolive': 'Colgate-Palmolive',\n",
    "\n",
    "    # Comcast\n",
    "    'comcast': 'Comcast Corp.',\n",
    "    'comcast corp': 'Comcast Corp.',\n",
    "\n",
    "    # Costco\n",
    "    'costco': 'Costco Wholesale Corp.',\n",
    "    'costco wholesale corp': 'Costco Wholesale Corp.',\n",
    "\n",
    "    # Disney\n",
    "    'disney': 'The Walt Disney Company',\n",
    "    'the walt disney company': 'The Walt Disney Company',\n",
    "\n",
    "    # Exxon\n",
    "    'exxon': 'Exxon Mobil Corp.',\n",
    "    'exxon mobil corp': 'Exxon Mobil Corp.',\n",
    "\n",
    "    # Facebook (aka Meta)\n",
    "    'facebook': 'Facebook Inc.',\n",
    "    'facebook inc': 'Facebook Inc.',\n",
    "\n",
    "    # FedEx\n",
    "    'fedex': 'FedEx Corporation',\n",
    "    'fedex corporation': 'FedEx Corporation',\n",
    "\n",
    "    # Ford\n",
    "    'ford': 'Ford Motor Company',\n",
    "    'ford motor company': 'Ford Motor Company',\n",
    "\n",
    "    # Goldman Sachs\n",
    "    'goldman sachs': 'Goldman Sachs Group',\n",
    "    'goldman sachs group': 'Goldman Sachs Group',\n",
    "\n",
    "    # Google / Alphabet – unify under Alphabet Inc. \n",
    "    'google': 'Alphabet Inc.',\n",
    "    'google inc': 'Alphabet Inc.',\n",
    "    'alphabet inc class a': 'Alphabet Inc.',\n",
    "    'alphabet inc class c': 'Alphabet Inc.',\n",
    "    # The next two lines handle parentheses in \"Alphabet Inc. (Class A)\" or (Class C)\n",
    "    'alphabet inc (class a)': 'Alphabet Inc.',\n",
    "    'alphabet inc (class c)': 'Alphabet Inc.',\n",
    "\n",
    "    # IBM\n",
    "    'ibm': 'International Business Machines',\n",
    "    'international business machines': 'International Business Machines',\n",
    "\n",
    "    # Intel\n",
    "    'intel': 'Intel Corp.',\n",
    "    'intel corp': 'Intel Corp.',\n",
    "\n",
    "    # JPMorgan\n",
    "    'jpmorgan': 'JPMorgan Chase & Co.',\n",
    "    'jpmorgan chase & co': 'JPMorgan Chase & Co.',\n",
    "\n",
    "    # Kroger\n",
    "    'kroger': 'Kroger Co.',\n",
    "    'kroger co': 'Kroger Co.',\n",
    "\n",
    "    # Mastercard\n",
    "    'mastercard': 'Mastercard Inc.',\n",
    "    'mastercard inc': 'Mastercard Inc.',\n",
    "\n",
    "    # McDonald's\n",
    "    \"mcdonald's\": \"McDonald's Corp.\",\n",
    "    \"mcdonald's corp\": \"McDonald's Corp.\",\n",
    "\n",
    "    # Microsoft\n",
    "    'microsoft': 'Microsoft Corp.',\n",
    "    'microsoft corp': 'Microsoft Corp.',\n",
    "\n",
    "    # Netflix\n",
    "    'netflix': 'Netflix Inc.',\n",
    "    'netflix inc': 'Netflix Inc.',\n",
    "\n",
    "    # Nike\n",
    "    'nike': 'Nike Inc.',\n",
    "    'nike inc': 'Nike Inc.',\n",
    "\n",
    "    # Oracle\n",
    "    'oracle': 'Oracle Corp.',\n",
    "    'oracle corp': 'Oracle Corp.',\n",
    "\n",
    "    # Procter & Gamble\n",
    "    'p&g': 'Procter & Gamble',\n",
    "    'procter & gamble': 'Procter & Gamble',\n",
    "\n",
    "    # Pepsi\n",
    "    'pepsi': 'PepsiCo Inc.',\n",
    "    'pepsico inc': 'PepsiCo Inc.',\n",
    "\n",
    "    # Pfizer\n",
    "    'pfizer': 'Pfizer Inc.',\n",
    "    'pfizer inc': 'Pfizer Inc.',\n",
    "\n",
    "    # Salesforce\n",
    "    'salesforcecom': 'salesforce.com',  # or \"Salesforce, Inc.\" if you prefer\n",
    "    # (choose one form; “Salesforce, Inc.” is the modern legal name)\n",
    "    'salesforce.com': 'salesforce.com',\n",
    "\n",
    "    # Starbucks\n",
    "    'starbucks': 'Starbucks Corp.',\n",
    "    'starbucks corp': 'Starbucks Corp.',\n",
    "\n",
    "    # T-Mobile\n",
    "    'tmobile': 'T-Mobile US',\n",
    "\n",
    "    # Tesla\n",
    "    'tesla inc': 'Tesla, Inc.',\n",
    "    'tesla, inc': 'Tesla, Inc.',\n",
    "    'tesla': 'Tesla, Inc.',\n",
    "\n",
    "    # UPS\n",
    "    'ups': 'United Parcel Service',\n",
    "    'united parcel service': 'United Parcel Service',\n",
    "\n",
    "    # Verizon\n",
    "    'verizon': 'Verizon Communications',\n",
    "    'verizon communications': 'Verizon Communications',\n",
    "\n",
    "    # Visa\n",
    "    'visa': 'Visa Inc.',\n",
    "    'visa inc': 'Visa Inc.'\n",
    "}\n",
    "\n",
    "def consolidate_company_name(company_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Return a canonical version of the company_name if it matches\n",
    "    a known synonym, otherwise return the name as-is.\n",
    "    \"\"\"\n",
    "    # Convert to lowercase, remove commas and periods, etc. (except & or apostrophes).\n",
    "    normalized = re.sub(r'[.,]', '', company_name.strip().lower())\n",
    "\n",
    "    # Look up in synonyms dictionary\n",
    "    return synonyms.get(normalized, company_name)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "# EXAMPLE USAGE:\n",
    "df['Consolidated_Company_Name'] = df['Company_Name'].apply(consolidate_company_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "eaacbd5c-be53-49b4-b79c-da89370fed84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Created_at</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Stock_ticker</th>\n",
       "      <th>Score</th>\n",
       "      <th>Source</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Consolidated_Company_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-29 23:41:16+00:00</td>\n",
       "      <td>Mainstream media has done an amazing job at br...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.549933</td>\n",
       "      <td>Kenny</td>\n",
       "      <td>Tesla, Inc.</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Tesla, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-29 23:24:43+00:00</td>\n",
       "      <td>Tesla delivery estimates are at around 364k fr...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.104447</td>\n",
       "      <td>Kenny</td>\n",
       "      <td>Tesla, Inc.</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Tesla, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-29 23:18:08+00:00</td>\n",
       "      <td>3/ Even if I include 63.0M unvested RSUs as of...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.879566</td>\n",
       "      <td>Kenny</td>\n",
       "      <td>Tesla, Inc.</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Tesla, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-29 22:40:07+00:00</td>\n",
       "      <td>@RealDanODowd @WholeMarsBlog @Tesla Hahaha why...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.094424</td>\n",
       "      <td>Kenny</td>\n",
       "      <td>Tesla, Inc.</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Tesla, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-29 22:27:05+00:00</td>\n",
       "      <td>@RealDanODowd @Tesla Stop trying to kill kids,...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>-0.550417</td>\n",
       "      <td>Kenny</td>\n",
       "      <td>Tesla, Inc.</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Tesla, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868822</th>\n",
       "      <td>2018-09-01 14:11:07</td>\n",
       "      <td>As Apple INC $AAPL Share Value Rose, Waddell &amp;...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.934082</td>\n",
       "      <td>Ginger</td>\n",
       "      <td>apple</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Apple Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868823</th>\n",
       "      <td>2018-09-01 14:11:44</td>\n",
       "      <td>Contrasting Alphabet Inc Class A $GOOGL and Sy...</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>-1.074219</td>\n",
       "      <td>Ginger</td>\n",
       "      <td>Google Inc</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868824</th>\n",
       "      <td>2018-09-01 14:12:07</td>\n",
       "      <td>Nanoleaf's touch-sensitive Canvas light panels...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.943848</td>\n",
       "      <td>Ginger</td>\n",
       "      <td>apple</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Apple Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868825</th>\n",
       "      <td>2018-09-01 14:13:16</td>\n",
       "      <td>Financial Review: Synacor $SYNC &amp; Alphabet Inc...</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0.827637</td>\n",
       "      <td>Ginger</td>\n",
       "      <td>Google Inc</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868826</th>\n",
       "      <td>2018-09-01 14:13:22</td>\n",
       "      <td>This emerging #wearables #AugmentedReality dis...</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>-0.035889</td>\n",
       "      <td>Ginger</td>\n",
       "      <td>Google Inc</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1868827 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Created_at  \\\n",
       "0        2022-09-29 23:41:16+00:00   \n",
       "1        2022-09-29 23:24:43+00:00   \n",
       "2        2022-09-29 23:18:08+00:00   \n",
       "3        2022-09-29 22:40:07+00:00   \n",
       "4        2022-09-29 22:27:05+00:00   \n",
       "...                            ...   \n",
       "1868822        2018-09-01 14:11:07   \n",
       "1868823        2018-09-01 14:11:44   \n",
       "1868824        2018-09-01 14:12:07   \n",
       "1868825        2018-09-01 14:13:16   \n",
       "1868826        2018-09-01 14:13:22   \n",
       "\n",
       "                                                     Tweet Stock_ticker  \\\n",
       "0        Mainstream media has done an amazing job at br...         TSLA   \n",
       "1        Tesla delivery estimates are at around 364k fr...         TSLA   \n",
       "2        3/ Even if I include 63.0M unvested RSUs as of...         TSLA   \n",
       "3        @RealDanODowd @WholeMarsBlog @Tesla Hahaha why...         TSLA   \n",
       "4        @RealDanODowd @Tesla Stop trying to kill kids,...         TSLA   \n",
       "...                                                    ...          ...   \n",
       "1868822  As Apple INC $AAPL Share Value Rose, Waddell &...         AAPL   \n",
       "1868823  Contrasting Alphabet Inc Class A $GOOGL and Sy...        GOOGL   \n",
       "1868824  Nanoleaf's touch-sensitive Canvas light panels...         AAPL   \n",
       "1868825  Financial Review: Synacor $SYNC & Alphabet Inc...        GOOGL   \n",
       "1868826  This emerging #wearables #AugmentedReality dis...        GOOGL   \n",
       "\n",
       "            Score  Source Company_Name                  Sector  \\\n",
       "0        0.549933   Kenny  Tesla, Inc.  Consumer Discretionary   \n",
       "1        0.104447   Kenny  Tesla, Inc.  Consumer Discretionary   \n",
       "2        0.879566   Kenny  Tesla, Inc.  Consumer Discretionary   \n",
       "3        0.094424   Kenny  Tesla, Inc.  Consumer Discretionary   \n",
       "4       -0.550417   Kenny  Tesla, Inc.  Consumer Discretionary   \n",
       "...           ...     ...          ...                     ...   \n",
       "1868822  0.934082  Ginger        apple  Information Technology   \n",
       "1868823 -1.074219  Ginger   Google Inc  Communication Services   \n",
       "1868824  0.943848  Ginger        apple  Information Technology   \n",
       "1868825  0.827637  Ginger   Google Inc  Communication Services   \n",
       "1868826 -0.035889  Ginger   Google Inc  Communication Services   \n",
       "\n",
       "        Consolidated_Company_Name  \n",
       "0                     Tesla, Inc.  \n",
       "1                     Tesla, Inc.  \n",
       "2                     Tesla, Inc.  \n",
       "3                     Tesla, Inc.  \n",
       "4                     Tesla, Inc.  \n",
       "...                           ...  \n",
       "1868822                Apple Inc.  \n",
       "1868823             Alphabet Inc.  \n",
       "1868824                Apple Inc.  \n",
       "1868825             Alphabet Inc.  \n",
       "1868826             Alphabet Inc.  \n",
       "\n",
       "[1868827 rows x 8 columns]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "93e3e580-ed32-48e3-a414-3e38fc4bedeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['Consolidated_Company_Name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "a3052b00-0e86-4656-b68d-35c79b64bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ticker_synonyms = {\n",
    "    'GOOG': 'GOOGL',    # unify GOOG to GOOGL\n",
    "    'FB': 'META'        # unify FB to META\n",
    "    # etc. add more if needed\n",
    "}\n",
    "\n",
    "def consolidate_ticker(ticker: str) -> str:\n",
    "    \"\"\"\n",
    "    Return a canonical ticker if it matches a known duplicate,\n",
    "    otherwise return the original ticker.\n",
    "    \"\"\"\n",
    "    return ticker_synonyms.get(ticker, ticker)\n",
    "\n",
    "# Create a new column with consolidated tickers\n",
    "df['Consolidated_Ticker'] = df['Stock_ticker'].apply(consolidate_ticker)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "26f2d60d-5882-4508-a750-43c6afe153e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tesla, Inc.             430572\n",
       "Apple Inc.              389896\n",
       "Amazon.com Inc.         288154\n",
       "Alphabet Inc.           223877\n",
       "Microsoft Corp.         138347\n",
       "                         ...  \n",
       "Juniper Networks            92\n",
       "Grainger (W.W.) Inc.        92\n",
       "Sealed Air                  92\n",
       "Zoetis                      92\n",
       "CVS Health                  10\n",
       "Name: Consolidated_Company_Name, Length: 298, dtype: int64"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_counts = df['Consolidated_Company_Name'].value_counts()\n",
    "# company_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "d59d30f1-d027-4d25-8649-426b5f4d6348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_companies = company_counts[company_counts > 500].index\n",
    "df_filtered = df[df['Consolidated_Company_Name'].isin(filtered_companies)]\n",
    "len(set(df_filtered['Consolidated_Company_Name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "cbe36849-96f7-4fb6-9c19-1ff85ccf3734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AT&T Inc.',\n",
       " 'Adobe Inc.',\n",
       " 'Advanced Micro Devices Inc',\n",
       " 'Air Products & Chemicals Inc',\n",
       " 'Alphabet Inc.',\n",
       " 'Amazon.com Inc.',\n",
       " 'Apple Inc.',\n",
       " 'Bank of America Corp',\n",
       " 'Boeing Company',\n",
       " 'Broadcom Inc.',\n",
       " 'Carnival Corp.',\n",
       " 'Caterpillar Inc.',\n",
       " 'Chevron Corp.',\n",
       " 'Cisco Systems',\n",
       " 'Citigroup Inc.',\n",
       " 'Coca-Cola Company',\n",
       " 'Comcast Corp.',\n",
       " 'Costco Wholesale Corp.',\n",
       " 'Dow Inc.',\n",
       " 'Edwards Lifesciences',\n",
       " 'Eversource Energy',\n",
       " 'Exxon Mobil Corp.',\n",
       " 'Facebook Inc.',\n",
       " 'FedEx Corporation',\n",
       " 'Ford Motor Company',\n",
       " 'Goldman Sachs Group',\n",
       " 'Home Depot',\n",
       " 'Intel Corp.',\n",
       " 'International Business Machines',\n",
       " 'JPMorgan Chase & Co.',\n",
       " 'Johnson & Johnson',\n",
       " 'Kroger Co.',\n",
       " 'Mastercard Inc.',\n",
       " \"McDonald's Corp.\",\n",
       " 'Microsoft Corp.',\n",
       " 'Morgan Stanley',\n",
       " 'Netflix Inc.',\n",
       " 'Newmont Corporation',\n",
       " 'Nike Inc.',\n",
       " 'Nvidia Corporation',\n",
       " 'Oracle Corp.',\n",
       " 'PayPal',\n",
       " 'PepsiCo Inc.',\n",
       " 'Pfizer Inc.',\n",
       " 'Procter & Gamble',\n",
       " 'Starbucks Corp.',\n",
       " 'T-Mobile US',\n",
       " 'Tesla, Inc.',\n",
       " 'The Bank of New York Mellon',\n",
       " 'The Walt Disney Company',\n",
       " 'Twitter Inc.',\n",
       " 'United Health Group Inc.',\n",
       " 'United Parcel Service',\n",
       " 'Verizon Communications',\n",
       " 'Visa Inc.',\n",
       " 'Walmart',\n",
       " 'Wells Fargo'}"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_filtered['Consolidated_Company_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "cd7d37e7-988c-46f9-85df-aedc2e781f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "gics_sub_industry_map = {\n",
    "    \"AT&T Inc.\": \"Integrated Telecommunication Services\",\n",
    "    \"Adobe Inc.\": \"Application Software\",\n",
    "    \"Advanced Micro Devices Inc\": \"Semiconductors\",\n",
    "    \"Air Products & Chemicals Inc\": \"Industrial Gases\",\n",
    "    \"Alphabet Inc.\": \"Interactive Media & Services\",\n",
    "    \"Amazon.com Inc.\": \"Internet & Direct Marketing Retail\",\n",
    "    \"Apple Inc.\": \"Technology Hardware, Storage & Peripherals\",\n",
    "    \"Bank of America Corp\": \"Diversified Banks\",\n",
    "    \"Boeing Company\": \"Aerospace & Defense\",\n",
    "    \"Broadcom Inc.\": \"Semiconductors\",\n",
    "    \"Carnival Corp.\": \"Hotels, Resorts & Cruise Lines\",\n",
    "    \"Caterpillar Inc.\": \"Construction Machinery & Heavy Trucks\",\n",
    "    \"Chevron Corp.\": \"Integrated Oil & Gas\",\n",
    "    \"Cisco Systems\": \"Communications Equipment\",\n",
    "    \"Citigroup Inc.\": \"Diversified Banks\",\n",
    "    \"Coca-Cola Company\": \"Soft Drinks\",\n",
    "    \"Comcast Corp.\": \"Cable & Satellite\",\n",
    "    \"Costco Wholesale Corp.\": \"Hypermarkets & Super Centers\",\n",
    "    \"Dow Inc.\": \"Commodity Chemicals\",\n",
    "    \"Edwards Lifesciences\": \"Health Care Equipment\",\n",
    "    \"Eversource Energy\": \"Electric Utilities\",\n",
    "    \"Exxon Mobil Corp.\": \"Integrated Oil & Gas\",\n",
    "    \"Facebook Inc.\": \"Interactive Media & Services\",\n",
    "    \"FedEx Corporation\": \"Air Freight & Logistics\",\n",
    "    \"Ford Motor Company\": \"Automobile Manufacturers\",\n",
    "    \"Goldman Sachs Group\": \"Investment Banking & Brokerage\",\n",
    "    \"Home Depot\": \"Home Improvement Retail\",\n",
    "    \"Intel Corp.\": \"Semiconductors\",\n",
    "    \"International Business Machines\": \"IT Consulting & Other Services\",\n",
    "    \"JPMorgan Chase & Co.\": \"Diversified Banks\",\n",
    "    \"Johnson & Johnson\": \"Pharmaceuticals\",\n",
    "    \"Kroger Co.\": \"Food Retail\",\n",
    "    \"Mastercard Inc.\": \"Data Processing & Outsourced Services\",\n",
    "    \"McDonald's Corp.\": \"Restaurants\",\n",
    "    \"Microsoft Corp.\": \"Systems Software\",\n",
    "    \"Morgan Stanley\": \"Investment Banking & Brokerage\",\n",
    "    \"Netflix Inc.\": \"Movies & Entertainment\",\n",
    "    \"Newmont Corporation\": \"Gold\",\n",
    "    \"Nike Inc.\": \"Footwear\",\n",
    "    \"Nvidia Corporation\": \"Semiconductors\",\n",
    "    \"Oracle Corp.\": \"Systems Software\",\n",
    "    \"PayPal\": \"Data Processing & Outsourced Services\",\n",
    "    \"PepsiCo Inc.\": \"Soft Drinks\",\n",
    "    \"Pfizer Inc.\": \"Pharmaceuticals\",\n",
    "    \"Procter & Gamble\": \"Household Products\",\n",
    "    \"Starbucks Corp.\": \"Restaurants\",\n",
    "    \"T-Mobile US\": \"Wireless Telecommunication Services\",\n",
    "    \"Tesla, Inc.\": \"Automobile Manufacturers\",\n",
    "    \"The Bank of New York Mellon\": \"Asset Management & Custody Banks\",\n",
    "    \"The Walt Disney Company\": \"Movies & Entertainment\",\n",
    "    \"Twitter Inc.\": \"Interactive Media & Services\",\n",
    "    \"United Health Group Inc.\": \"Managed Health Care\",\n",
    "    \"United Parcel Service\": \"Air Freight & Logistics\",\n",
    "    \"Verizon Communications\": \"Integrated Telecommunication Services\",\n",
    "    \"Visa Inc.\": \"Data Processing & Outsourced Services\",\n",
    "    \"Walmart\": \"Hypermarkets & Super Centers\",\n",
    "    \"Wells Fargo\": \"Diversified Banks\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "5dfbe3d8-2c5b-442c-ba20-773f4854a7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17405/2377444709.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered[\"GICS_Sub_Industry\"] = df_filtered[\"Consolidated_Company_Name\"].map(gics_sub_industry_map).fillna(\"Unknown\")\n"
     ]
    }
   ],
   "source": [
    "df_filtered[\"GICS_Sub_Industry\"] = df_filtered[\"Consolidated_Company_Name\"].map(gics_sub_industry_map).fillna(\"Unknown\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "1d4023de-bbae-4403-8591-8de100692c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv('/home/ginger/code/gderiddershanghai/DVA_Team_173/data_full/processed/iteration2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "f26f556b-7542-4289-8f42-15aba6a8895d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '31/01/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '28/02/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '31/03/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '28/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '29/04/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '31/05/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '30/06/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '31/07/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '31/08/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '29/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '30/09/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '31/10/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '30/11/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '29/12/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '30/12/2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '18/10/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '19/10/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '20/10/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '21/10/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '22/10/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '23/10/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '24/10/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '25/10/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '27/10/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '28/10/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '29/10/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '30/10/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '31/10/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '13/09/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '14/09/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '15/09/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '16/09/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '17/09/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '18/09/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '19/09/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '20/09/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '21/09/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '30/09/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '22/09/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '23/09/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '24/09/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '25/09/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '26/09/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '27/09/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '28/09/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '29/09/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '13/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '14/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '15/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '16/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '17/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '18/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '19/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '20/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '21/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '22/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '23/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '24/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '25/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '26/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '27/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '28/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '29/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '30/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '31/07/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '13/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '14/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '15/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '16/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '17/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '18/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '19/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '20/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '21/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '22/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '23/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '24/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '25/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '26/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '27/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '28/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '29/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '30/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: UserWarning: Parsing '31/08/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n",
      "/tmp/ipykernel_17405/175842938.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])\n"
     ]
    }
   ],
   "source": [
    "df_filtered[\"Created_at\"] = pd.to_datetime(df_filtered[\"Created_at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "fbf58f2c-b41e-403b-a72e-0b946b4abe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv('/home/ginger/code/gderiddershanghai/DVA_Team_173/data_full/processed/iteration3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "c73cf52d-c2db-43df-b338-2e50ca9d138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['Chevron Corp.',\n",
    " 'Cisco Systems',\n",
    " 'Citigroup Inc.',\n",
    " 'Coca-Cola Company',\n",
    " 'Comcast Corp.',\n",
    " 'Costco Wholesale Corp.',\n",
    " 'Dow Inc.',\n",
    " 'Edwards Lifesciences',\n",
    " 'Eversource Energy',\n",
    " 'Exxon Mobil Corp.',\n",
    " 'Facebook Inc.',\n",
    " 'FedEx Corporation',\n",
    " # 'Ford Motor Company',\n",
    " 'Goldman Sachs Group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "234f4dce-7b7a-4f9b-ab58-912eb27d9423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Created_at</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Stock_ticker</th>\n",
       "      <th>Score</th>\n",
       "      <th>Source</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Consolidated_Company_Name</th>\n",
       "      <th>Consolidated_Ticker</th>\n",
       "      <th>GICS_Sub_Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244502</th>\n",
       "      <td>2018-01-10 00:00:00</td>\n",
       "      <td>RT @itsKammy_G: \"The childhood of many will be...</td>\n",
       "      <td>DIS</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>Jason</td>\n",
       "      <td>Disney</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>The Walt Disney Company</td>\n",
       "      <td>DIS</td>\n",
       "      <td>Movies &amp; Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539500</th>\n",
       "      <td>2018-05-01 23:32:32</td>\n",
       "      <td>Shortfall in battery metals to slow electric v...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.953613</td>\n",
       "      <td>Ginger</td>\n",
       "      <td>Tesla Inc</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Tesla, Inc.</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>Automobile Manufacturers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482424</th>\n",
       "      <td>2020-04-09 12:26:31+00:00</td>\n",
       "      <td>$JNJ swiftly 3 weeks higher took the month up ...</td>\n",
       "      <td>JNJ</td>\n",
       "      <td>0.958321</td>\n",
       "      <td>Carina</td>\n",
       "      <td>Johnson &amp; Johnson</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Johnson &amp; Johnson</td>\n",
       "      <td>JNJ</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Created_at  \\\n",
       "244502         2018-01-10 00:00:00   \n",
       "1539500        2018-05-01 23:32:32   \n",
       "482424   2020-04-09 12:26:31+00:00   \n",
       "\n",
       "                                                     Tweet Stock_ticker  \\\n",
       "244502   RT @itsKammy_G: \"The childhood of many will be...          DIS   \n",
       "1539500  Shortfall in battery metals to slow electric v...         TSLA   \n",
       "482424   $JNJ swiftly 3 weeks higher took the month up ...          JNJ   \n",
       "\n",
       "            Score  Source       Company_Name                  Sector  \\\n",
       "244502   0.600000   Jason             Disney  Communication Services   \n",
       "1539500  0.953613  Ginger          Tesla Inc  Consumer Discretionary   \n",
       "482424   0.958321  Carina  Johnson & Johnson             Health Care   \n",
       "\n",
       "        Consolidated_Company_Name Consolidated_Ticker  \\\n",
       "244502    The Walt Disney Company                 DIS   \n",
       "1539500               Tesla, Inc.                TSLA   \n",
       "482424          Johnson & Johnson                 JNJ   \n",
       "\n",
       "                GICS_Sub_Industry  \n",
       "244502     Movies & Entertainment  \n",
       "1539500  Automobile Manufacturers  \n",
       "482424            Pharmaceuticals  "
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "80d38f63-1214-427a-88c7-8db61bc83b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_filtered['Consolidated_Company_Name']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
